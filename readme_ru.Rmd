---
title: "Стандартизованная процедура обработки почвенных ампликонных библиотек"
output: 
  github_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Введение

Данная операционная процедура представляет собой полный цикл обработки почвенных ампликонных библиотек, включающих обработку сырых прочтений, их нормализацию, анализ параметров и уровней разнообразия, а также визуализацию и статистический анализ дифференциальной представленности и обилия микробных таксонов, маркирующих определенную стадию почвообразовательного процесса.
В качестве инструмента для анализа кинетики и направления почвенного экогенеза и сопряженной эволюции микробиома предложена и стандартизирована процедура определения «корового» («консервативного»), и акцессорного, вариабельного/индикаторного компонента, характерного для каждой стадии развития/регенерации почвы.
Полученная в результате платформа обеспечивает, таким образом, стандартизацию рабочего процесса обработки данных по структуре почвенного метагенома и изучения ведущих факторов и механизмов в изменении состава микробиома со временем и дифференциацией почвенных горизонтов, включая процессинг сырых необработанных последовательностей ДНК и интегральную оценку параметров состава и разнообразия микробиомов.
Большинство операций представляет собой обращения к сторонним библиотекам и их функциям. В данном README мы обсудим самый общий вариант анализа почвенного сообщества - для точной настройки или за подробностями прочтите и/или внесите исправления в соответствующие функции

В рамках проекта использованы следующие библиотеки:

* [dada2](https://benjjneb.github.io/dada2/tutorial.html)
* [Biostrings](https://bioconductor.org/packages/release/bioc/html/Biostrings.html)
* [DECIPHER](https://bioconductor.org/packages/release/bioc/html/DECIPHER.html)
* [phyloseq](https://joey711.github.io/phyloseq/)
* [ggplot2](https://ggplot2.tidyverse.org/)
* [ggpubr](https://rpkgs.datanovia.com/ggpubr/)
* [ape](https://cran.r-project.org/web/packages/ape/index.html)
* [plyr](https://www.rdocumentation.org/packages/plyr/versions/1.8.6)
* [dplyr](https://dplyr.tidyverse.org/)
* [DESeq2](http://bioconductor.org/packages/release/bioc/html/DESeq2.html)


---

## Импорт библиотек и функций

Импортируйте нужные библиотеки. При необходимости, установите их. Также задайте рабочую директорию и экспортируйте функции

В качестве тестового датасета мы будем использовать ампликонные прочтения песчаных почв. В сравнении будут участвовать песчаные почвы с морозобойными клиньями (shooting range) и зарастающая песчаная почва (Anclav)

```{r message=FALSE, warning=FALSE}
library(dada2)
library(Biostrings)
library(DECIPHER)
library(phyloseq)
library(ggplot2)
library(ggpubr)
library(ape)
library(plyr)
library(dplyr)
library(DESeq2)

source('functions.R')

setwd('/home/alexey/Analysis/16s-amplicon-processing/')
```


---

## Dada2 обработка прочтений

Для работы нужно указать пусть до исходных файлов, а также предоставить метаданные (информацию об образцах). В нашем примере исходные файлы находятся в папке `raw`, метаданные в файле `metadata.csv`.

Функции из этого модуля:

`dada2_processing(raw_files_path, cores=TRUE, trimLeft = c(19, 20)`

* `raw_files_path` - путь к исходным файлам .fastq.gz
* `cores` - количество ядер для анализа. Используйте TRUE чтобы задать все доступные
* `trimLeft` - если требуется обрезать праймеры, используйте этот аргумент в формате c(len_forward, len_reverse)
* возвращает таблицу ASV и их представленности по образцам

`rename_by_metadata(seqtab, mdat)`

* `seqtab` - таблица ASV
* `mdat` - датафрейм с метаданными (используйте колонку Filename для имен файлов)
* возвращает ASV-таблицу с переименованными образцами

`dada2_assign_taxonomy(seqtab, set_train_path, train_set_species_path, cores = TRUE)`

* `set_train_path` - путь до натренированных fasta-файлов базы референсов SILVA (см. детали в пайплайне dada2 [здесь](https://benjjneb.github.io/dada2/tutorial.html))
* `train_set_species_path` - путь до натренированных fasta-файлов отдельных видов (см. детали в пайплайне dada2 [здесь](https://benjjneb.github.io/dada2/tutorial.html))
* `cores` - количество ядер для анализа. Используйте TRUE чтобы задать все доступные
* возвращает таблицу таксономии


```{r cache=TRUE}

mdat <- read.csv('metadata.csv', sep = '\t')
rownames(mdat) <- mdat$SampleID
mdat


seqtab <- dada2_processing_reads(raw_files_path = 'raw')
seqtab <- rename_by_metadata(seqtab, mdat)

taxa <- dada2_assign_taxonomy(seqtab = seqtab, set_train_path = '/home/alexey/tax_n_refs/silva_nr_v132_train_set.fa.gz', 
                           train_set_species_path = '/home/alexey/tax_n_refs/silva_species_assignment_v132.fa.gz')

```


---

## Создание объекта phyloseq, добавление информации о дереве

На этом шаге нужно создать phyloseq объект, который будет содержать всю информацию о нашем датасете. Обратите внимание, что все компоненты должны иметь одинаковые имена

```{r}
ps <- phyloseq(otu_table(seqtab, taxa_are_rows=FALSE), 
               sample_data(mdat), 
               tax_table(taxa))

ps

```

Также на этом этапе мы экспортируем файл fasta с последовательностями для каждого ASV и включаем информацию о дереве в объект phyloseq. Мы не выполняем построение дерева в R из-за недостаточно эффективных алгоритмов и рекомендуем выполнять его с использованием Fasttree в пакете QIIME2.

`create_ASV_references(ps_object, write = TRUE)`

* `ps_object` - объект phyloseq
* `write` - если True, записывает `refseqs.fasta` файл, содержащий референсы для каждой ASV
* возвращает объект phyloseq с отдельно записанными референсами и именами ASV вида ASV%%%


```{r}
ps <- create_ASV_references(ps)

tree <- read_tree('tree.nwk')
ps <- merge_phyloseq(ps, phy_tree(tree))

ps

```


---

## Базовые статистики и сохранение данных

Осмотрите получившийся объект для получения представления о том, как много таксонов в датасете, каковы их категории, и каково количество прочтений в одном образце. Также сохраните phyloseq объект в файл. При необходимости, его можно загрузить обратно в переменную

```{r}
sample_names(ps) # Имена образцов
rank_names(ps) # Таксономические ранги

sample_sums(ps) # Сумма прочтений по образцам


tax_table(ps)[1:5, 1:4] # Таблица таксономии
otu_table(ps)[1:4, 1:5] # Таблица образцов

saveRDS(ps, "ps.RData")
```


---

## Нормализация

Нормализация данных - область дискуссий, но в данном случае мы определим такую возможность. Реализованы варианты относительной численности и простого разрежения в качестве вариантов, но в будущем планируется использование varstab и log-relative

`normaize_phyloseq(ps_object, method='rarefaction')`

* `ps_object` - объект phyloseq
* `method` - методика нормализации. Варианты: "rarefaction", "relative"
* возвращает объект phyloseq с нормализованными данными


```{r}
ps.n <- normalize_phyloseq(ps, method='rarefaction')
```


---

## Барграфы

Эта функция задает барграф относительной численности различных таксонов в наборе данных. Функция возвращает объект ggplot, поэтому при необходимости можно добавить сетку фасетов для категории метаданных.

`bargraphps_object, rank, threshold=0.05)`

* `ps_object` - объект phyloseq
* `rank` - таксономический уровень для построения
* `threshold` - таксоны с относительной численностью менее threshold будут объединены в категорию "< abund."
* возвращает график ggplot


```{r}
bargraph(ps, 'Phylum', 0.03)

bargraph(ps, 'Phylum', 0.03) + facet_grid(~ Source, scale = 'free_x')
```


## Альфа разнообразие

Данные функции позволяют рассчитать значения индексов альфа-разнообразия и создать график

`alpha_div(ps, metric, group)`

* `ps` - объект phyloseq
* `metric` - группа метрик. Возможные варианты -  "Observed", "Chao1", "ACE", "Shannon", "Simpson", "InvSimpson", "Fisher" или их сочетания
* `group` - Дополнительная колонка из метаданных, которая будет включена в итоговую таблицу
* возвращает датафрейм с индексами альфа-разнообразия


`plot_alpha(ps, metric, group)`

* `ps` - объект phyloseq
* `metric` - группа метрик. Возможные варианты - один из "Observed", "Chao1", "ACE", "Shannon", "Simpson", "InvSimpson", "Fisher"
* `group` - Дополнительная колонка из метаданных для группировки образцов
* возвращает боксплот ggplot с точками отдельных индексов
 

```{r}
alpha_div(ps.n, c("Observed", "Simpson", "Shannon"), "Source")


ggarrange(plot_alpha(ps.n, "Observed", "Source"),
          plot_alpha(ps.n, "Simpson", "Source"), plot_alpha(ps.n, "Shannon", "Source"),
          nrow = 1, ncol = 3)

```


---

## Бета разнообразие

Небольшая функция для отрисовки бета-разнообразия

`beta_plot(ps, metric, group, method='PCoA')`

* `ps` - объект phyloseq
* `metric` - метрика. Возможные варианты: "bray", "wunifrac", "unifrac"
* `group` - Колонка из метаданных, определяющая окраску точек
* `method` - метод ординации. Возможные варианты: "PCoA", "NMDS"
* возвращает скаттерплот ggplot ординации образцов датасета


```{r}
beta_plot <- function(ps, metric, group, method='PCoA'){
  ps.prop <- transform_sample_counts(ps, function(x) x/sum(x))
  ord.nmds.bray <- ordinate(ps.prop, method=method, distance=metric)
  plot_ordination(ps.prop, ord.nmds.bray, color = group, title=metric) +
    geom_point(size=3, alpha=0.7) + labs() +
    theme_light()
}

beta_plot(ps, "bray", "Source")
```


## Дифференциальная представленность

Здесь мы пытаемся найти ASV, численность которых существенно различается в сравнении двух категорий. Для этого воспользуемся пакетом DeSEQ2. В этой функции мы выполняем сравнение двух групп и возвращаем таблицу ASV, значительно отличающихся друг от друга (p-adj <0,05) вместе с метриками DeSEQ2.

`sig_table(ps_object, formula)`

* `ps_object` - объект phyloseq
* `formula` - формула ~var_name для разбиения датасета на 2 группы (в нашем случае - ~Source)
* возвращает датафрейм ASV, а также их параметы при сравнении DeSEQ2 и таксономию


`draw_sig_table(sig_table, taxa)`

* `sig_table` - таблица достоверно меняющихся ASV (используются колонки log2FoldChange и baseMean)
* `taxa` - таксономический уровень для построения


```{r message=FALSE, warning=FALSE}
table <- sig_table(ps, ~Source)
table[1:6,1:9]


draw_sig_table(table, 'Phylum')
```

---

## Сети

Этот раздел в разработке. Вы можете заглянуть в `drafts.R` за любой интересующей информацией